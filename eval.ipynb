{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = html2text.HTML2Text(bodywidth=0)\n",
    "h.ignore_links = True\n",
    "h.ignore_images = True\n",
    "\n",
    "def parse_project(project_url):\n",
    "    with urlopen(project_url) as response:\n",
    "        soup = BeautifulSoup(response, \"html.parser\")\n",
    "    software_header = soup.find(\"header\", {\"id\": \"software-header\"})\n",
    "    title = software_header.find(\"h1\").text.strip()\n",
    "    info = software_header.find(\"p\").text.strip()\n",
    "    description = \"\"\n",
    "    built_with = \"\"\n",
    "    app_details = soup.find(\"div\", {\"id\": \"app-details-left\"})\n",
    "    for d in app_details.find_all(\"div\"):\n",
    "        if d.get(\"id\") == \"built-with\":\n",
    "            built_with = h.handle(str(d)).strip()\n",
    "        elif not d.get(\"id\"):\n",
    "            description = h.handle(str(d)).strip()\n",
    "    return [title, info, description, built_with]\n",
    "\n",
    "\n",
    "def parse_projects(pages=[1]):\n",
    "    links = []\n",
    "    for page in pages:\n",
    "        with urlopen(f\"https://anthropiclondon.devpost.com/project-gallery?page={page}\") as response:\n",
    "            soup = BeautifulSoup(response, \"html.parser\")\n",
    "            for e in soup.find_all(\"a\", {\"class\": \"block-wrapper-link fade link-to-software\"}):\n",
    "                links.append(e[\"href\"])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = parse_projects([1, 2, 3])\n",
    "len(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for i, project in enumerate(projects):\n",
    "    print(i, project)\n",
    "    data.append([project] + parse_project(project))\n",
    "df = pd.DataFrame(data=data, columns=[\"url\", \"title\", \"info\", \"description\", \"built_with\"])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"projects.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "\n",
    "anthropic = Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_prompt = f\"{HUMAN_PROMPT} You are an independent and objective judge at AI hackathon. To create a new project, all participants followed the hackathon instructions specified in the XML tags <hackathon_instructions></hackathon_instructions>. Your task as the judge is to select the best project according to creteria specified in the XML tags <judge_creteria></judge_creteria>. The projects descriptions specified using Markdown formatted text in the XML tags <project1_overview></project1_overview> and <project2_overview></project2_overview>.\"\n",
    "hackathon_instructions = \"\"\"Here is the hackathon instructions, in <hackathon_instructions></hackathon_instructions> XML tags:\n",
    "<hackathon_instructions>\n",
    "The hackathon challenge is to build & innovate with the power of Claude 2. Claude's advanced natural language capabilities enable a huge range of possibilities. You could create an AI assistant to increase government transparency, provide helpful to businesses, or detect misinformation online. Claude's strong reasoning skills also lend themselves well to automating bureaucratic processes to improve efficiency.\n",
    "Get creative with what you build! It could be a website, app, or voice experience powered by the Claude API. The judges will favor projects that demonstrate technical innovation but also have a clear purpose and benefit.\n",
    "Build a Claude 2-enabled app that is relevant to Anthropic's mission, useful for startups and businesses, and good for the world.\n",
    "Winners will be selected based on social impact/future potential, technical implementation, creativity, and pitching quality. Let's use this chance to build AI that makes a positive difference.\n",
    "The judges will favor projects that demonstrate technical innovation but also have a clear purpose and benefit.\n",
    "</hackathon_instructions>\"\"\"\n",
    "judging_creteria = \"\"\"Here is the judging creteria, in <judging_creteria></judging_creteria> XML tags:\\n<judging_creteria>\n",
    "1. Creativity: Is the project's concept innovative and unique? How good is the idea? Does this solve a real problem?\n",
    "2. Implementation: How well has the team technically implemented the idea?\n",
    "3. Potential: What is the project's long-term potential for success, growth and impact? Will you keep working on this?\n",
    "4. Pitch: How effectively does the team present their project? Is this a compelling startup or OSS?\n",
    "</judging_creteria>\"\"\"\n",
    "judge_instruction = f\"Please choose the project that best matches the judging criteria. Output only one project number either #1 or #2. {AI_PROMPT} #\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"projects.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_overview(project):\n",
    "    return f\"# {project.title}\\n\\n{project['info']}\\n\\n{project.description}\\n\\n{project.built_with}\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_project_overview(df.sample(1).iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dist = np.zeros((len(df), len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"results.csv\", index_col=\"vs\")\n",
    "results = {k: str(v.score) for k, v in results.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in range(len(df)):\n",
    "    project1_text = get_project_overview(df.iloc[i])\n",
    "    print(df.iloc[i].title)\n",
    "    for j in tqdm(range(len(df))):\n",
    "        project2_text = get_project_overview(df.iloc[j])\n",
    "\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        pair_key = df.iloc[i].title + \" vs \" + df.iloc[j].title\n",
    "\n",
    "        if pair_key in results:\n",
    "            result = results[pair_key]\n",
    "        else:\n",
    "\n",
    "            project1_overview = \"Here is the overview of project #1, in <project1_overview></project1_overview> XML tags:\\n<project1_overview>\" + project1_text + \"</project1_overview>\"\n",
    "            project2_overview = \"Here is the overview of project #2, in <project2_overview></project2_overview> XML tags:\\n<project2_overview>\" + project2_text + \"</project2_overview>\"\n",
    "\n",
    "            prompt = [\n",
    "                role_prompt,\n",
    "                hackathon_instructions,\n",
    "                project1_overview,\n",
    "                project2_overview,\n",
    "                judging_creteria,\n",
    "                judge_instruction,\n",
    "            ]\n",
    "            prompt = \"\\n\\n\".join(prompt)\n",
    "\n",
    "            completion = anthropic.completions.create(\n",
    "                model=\"claude-2\",\n",
    "                temperature=0,\n",
    "                max_tokens_to_sample=1,\n",
    "                prompt=prompt,\n",
    "            )\n",
    "            \n",
    "            result = completion.completion\n",
    "        \n",
    "        if result == \"1\":\n",
    "            dist[i, j] = 1\n",
    "        elif result == \"2\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected result: {result}\")\n",
    "        \n",
    "        results[pair_key] = result\n",
    "\n",
    "    pd.DataFrame(results.items(), columns=[\"vs\", \"score\"]).to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_final = dist - dist.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = dist_final.sum(axis=1) / (len(df) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"score\", ascending=False)[[\"score\", \"title\", \"url\"]].to_csv(\"scores.csv\", index=False, float_format=\"%.2f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
